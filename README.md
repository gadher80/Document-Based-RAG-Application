# ğŸ“„ Document-Based RAG Application

A Streamlit-based Retrieval-Augmented Generation RAG application that allows you to chat with your PDF documents. The app supports both Online mode using OpenAI models and Offline mode using a local Ollama LLM, making it flexible for experimentation and learning.

---

## ğŸš€ Features

* Chat with multiple PDF documents
* Retrieval-Augmented Generation using LangChain
* Vector storage with Chroma DB
* HuggingFace sentence transformer embeddings
* Toggle between Online OpenAI and Offline Ollama models
* Clean and simple Streamlit UI with custom CSS

---

## ğŸ§  Tech Stack

* Python
* Streamlit
* LangChain
* Chroma Vector Database
* HuggingFace Embeddings
* OpenAI API
* Ollama

---

## ğŸ“ Project Structure

```
Document-Based-RAG-Application/
â”‚â”€â”€ data/                 # PDF documents
â”‚â”€â”€ chroma_db/            # Vector database storage
â”‚â”€â”€ style.css             # Custom UI styling
â”‚â”€â”€ doc.py                # Main Streamlit application
â”‚â”€â”€ requirements.txt      # Python dependencies
â”‚â”€â”€ .env.example          # Environment variable template
â”‚â”€â”€ .gitignore
â”‚â”€â”€ README.md
```

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository

```
git clone https://github.com/gadher80/Document-Based-RAG-Application.git
cd Document-Based-RAG-Application
```

---

### 2ï¸âƒ£ Create Virtual Environment

```
python -m venv venv
venv\Scripts\activate
```

---

### 3ï¸âƒ£ Install Dependencies

```
pip install -r requirements.txt
```

---

### 4ï¸âƒ£ Environment Variables

Create a `.env` file in the project root

```
OPENAI_API_KEY=your_openai_api_key
```

For security, never commit `.env` to GitHub

---

## â–¶ï¸ Run the Application

```
streamlit run doc.py
```

The app will open in your browser

---

## ğŸ”„ Online vs Offline Mode

Online Mode

* Uses OpenAI Chat models
* Faster responses
* Higher quality answers
* Requires OpenAI API key

Offline Mode

* Uses local Ollama model
* No internet required
* Fully local inference
* Requires Ollama installed

---

## ğŸ§ª Ollama Setup

Install Ollama from

[https://ollama.com](https://ollama.com)

Pull required model

```
ollama pull llama3
```

Ensure Ollama is running before using Offline mode

---

## ğŸ“Œ Notes

* PDFs must be placed inside the `data/` folder
* Vector database persists in `chroma_db/`
* First run may take time due to embedding creation

---

## ğŸ“œ License

This project is for educational and learning purposes

---

## ğŸ™Œ Author

Hardik Gadher

Data Engineer | BI Engineer | AI Enthusiast
